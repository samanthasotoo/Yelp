{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce0b5ef",
   "metadata": {},
   "source": [
    "# Downloading JSON & Load to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179441dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "def download_json_and_load_into_dataframe(bucket, object_name, access_key, secret_key, num_rows_to_read=1000):\n",
    "    \"\"\"\n",
    "    Download a JSON file from an S3 bucket and load it into a pandas DataFrame\n",
    "\n",
    "    :param bucket: Bucket to download from\n",
    "    :param object_name: S3 object name\n",
    "    :param access_key: AWS Access Key ID\n",
    "    :param secret_key: AWS Secret Access Key\n",
    "    :return: DataFrame if successful, None otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an S3 client with the provided credentials\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=access_key,\n",
    "        aws_secret_access_key=secret_key\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Get the object from S3\n",
    "        response = s3_client.get_object(Bucket=bucket, Key=object_name)\n",
    "        # Read the content of the file\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "        # Convert the JSON string to a DataFrame\n",
    "        return pd.read_json(StringIO(content),lines=True, nrows=num_rows_to_read)\n",
    "    \n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available or invalid\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a587475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials and bucket details\n",
    "\n",
    "aws_access_key = 'AKIASI4QFQUWPUH54QFO'\n",
    "aws_secret_key = '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'\n",
    "bucket_name = 'yelp-review-ss'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb82282",
   "metadata": {},
   "source": [
    "# Transforming Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Downloading Business JSON file & into a Pandas DF\n",
    "object_name = 'yelp_academic_dataset_business.json'\n",
    "df_business = download_json_and_load_into_dataframe(bucket_name, object_name, aws_access_key, aws_secret_key)\n",
    "if df_business is not None:\n",
    "    df_business.head()\n",
    "else:\n",
    "    print(\"Failed to load data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Duplicate Values\n",
    "df_business_unique = df_business.drop_duplicates(subset=['business_id'])\n",
    "df_business_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1764d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Business Dimension\n",
    "\n",
    "dim_business = df_business_unique.drop('hours', axis=1)\n",
    "\n",
    "from pandas import json_normalize\n",
    "\n",
    "dim_business['attributes'] = dim_business['attributes'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "attributes_df = json_normalize(dim_business['attributes'].dropna())\n",
    "\n",
    "dim_business = dim_business.join(attributes_df)\n",
    "dim_business = dim_business.drop('attributes', axis=1)\n",
    "\n",
    "dim_business.columns = dim_business.columns.str.lower()\n",
    "\n",
    "dim_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "columns_to_fix = ['acceptsinsurance', 'corkage', 'restaurantsgoodforgroups', \n",
    "                  'businessacceptsbitcoin', 'happyhour']\n",
    "\n",
    "# Replace 'None' with NaN for the specified columns\n",
    "for column in columns_to_fix:\n",
    "    dim_business[column] = dim_business[column].replace('None', np.nan)\n",
    "\n",
    "# If you need to convert these columns to a specific type, such as float or bool, do so here\n",
    "# For example, to convert them to float:\n",
    "# for column in columns_to_fix:\n",
    "#     df[column] = df[column].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a47a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_business = dim_business.drop('businessparking', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_business['wheelchairaccessible']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661f6f7",
   "metadata": {},
   "source": [
    "Writing dim_business to CSV & S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2925927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "dim_business.to_csv(csv_buffer, index=False)\n",
    "csv_content = csv_buffer.getvalue()\n",
    "\n",
    "# S3 bucket and file path\n",
    "s3_bucket = 'yelp-review-ss'\n",
    "s3_key = 'clean/dim_business.csv'\n",
    "\n",
    "# Create a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    ")\n",
    "\n",
    "# Upload the CSV content to S3\n",
    "s3 = session.resource('s3')\n",
    "s3.Object(s3_bucket, s3_key).put(Body=csv_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992501a",
   "metadata": {},
   "source": [
    "# Transforming Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = 'yelp_academic_dataset_tip.json'\n",
    "df_tip = download_json_and_load_into_dataframe(bucket_name, object_name, aws_access_key, aws_secret_key)\n",
    "if df_tip is not None:\n",
    "    df_tip.head()\n",
    "else:\n",
    "    print(\"Failed to load data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip.drop('text', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44c009",
   "metadata": {},
   "source": [
    "Write Tip to CSV & S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab74b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Tip to S3\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df_tip.to_csv(csv_buffer, index=False)\n",
    "csv_content = csv_buffer.getvalue()\n",
    "\n",
    "# S3 bucket and file path\n",
    "s3_bucket = 'yelp-review-ss'\n",
    "s3_key = 'clean/tip_fact.csv'\n",
    "\n",
    "# Create a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    ")\n",
    "\n",
    "# Upload the CSV content to S3\n",
    "s3 = session.resource('s3')\n",
    "s3.Object(s3_bucket, s3_key).put(Body=csv_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2df1ff",
   "metadata": {},
   "source": [
    "# Creating Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Date Dimension\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "def week_of_month(dt):\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "\n",
    "    cal = calendar.monthcalendar(year, month)\n",
    "    week_number = (day - 1) // 7 + 1\n",
    "    return week_number\n",
    "\n",
    "start_date = pd.to_datetime('2000-01-01')\n",
    "end_date = pd.to_datetime('2023-09-30')\n",
    "\n",
    "# Create a DataFrame for the date dimension\n",
    "date_dimension = pd.DataFrame({'date': pd.date_range(start_date, end_date, freq='H')})\n",
    "\n",
    "# Extract attributes\n",
    "date_dimension['year'] = date_dimension['date'].dt.year\n",
    "date_dimension['quarter'] = date_dimension['date'].dt.quarter\n",
    "date_dimension['month_number'] = date_dimension['date'].dt.month\n",
    "date_dimension['month_name'] = date_dimension['date'].dt.strftime('%B')\n",
    "date_dimension['day_number'] = date_dimension['date'].dt.day\n",
    "date_dimension['day_name'] = date_dimension['date'].dt.strftime('%A')\n",
    "date_dimension['hour'] = date_dimension['date'].dt.hour\n",
    "date_dimension['date_isoformat'] = date_dimension['date'].apply(lambda x: x.isoformat())\n",
    "date_dimension['date_intformat'] = date_dimension['date'].dt.strftime('%Y%m%d%H')\n",
    "\n",
    "# Add week of the month and week of the year\n",
    "date_dimension['week_of_month'] = date_dimension['date'].apply(week_of_month)\n",
    "date_dimension['week_of_year'] = date_dimension['date'].dt.strftime('%U')\n",
    "\n",
    "date_dimension.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f073777",
   "metadata": {},
   "source": [
    "Send to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Date to S3\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "date_dimension.to_csv(csv_buffer, index=False)\n",
    "csv_content = csv_buffer.getvalue()\n",
    "\n",
    "# S3 bucket and file path\n",
    "s3_bucket = 'yelp-review-ss'\n",
    "s3_key = 'clean/dim_date.csv'\n",
    "\n",
    "# Create a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    ")\n",
    "\n",
    "# Upload the CSV content to S3\n",
    "s3 = session.resource('s3')\n",
    "s3.Object(s3_bucket, s3_key).put(Body=csv_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5057dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
